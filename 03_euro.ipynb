{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 3: Bayesian Statistics\n",
    "\n",
    "[Bayesian Decision Analysis](https://allendowney.github.io/BayesianDecisionAnalysis/)\n",
    "\n",
    "Copyright 2021 Allen B. Downey\n",
    "\n",
    "License: [Attribution-NonCommercial-ShareAlike 4.0 International (CC BY-NC-SA 4.0)](https://creativecommons.org/licenses/by-nc-sa/4.0/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review\n",
    "\n",
    "In the previous notebook we extended the cookie problem with more bowls and I introduced an alternative to the Bayes table, a probability mass function (PMF), which is a useful way to represent and do computations with distributions.\n",
    "\n",
    "Here's the function I used to create a `Pmf`, given a sequence of quantities, `qs`, and the corresponding probabilities, `ps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pmf(qs, ps, **options):\n",
    "    \"\"\"Make a Series that represents a PMF.\n",
    "    \n",
    "    qs: sequence of quantities\n",
    "    ps: sequence of probabilities\n",
    "    options: keyword arguments passed to Series constructor\n",
    "    \n",
    "    returns: Pandas Series\n",
    "    \"\"\"\n",
    "    pmf = pd.Series(ps, index=qs, **options)\n",
    "    return pmf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the function that performs a Bayesian update, given a sequence of likelihoods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_update(pmf, likelihood):\n",
    "    \"\"\"Do a Bayesian update.\n",
    "    \n",
    "    pmf: Series that represents the prior\n",
    "    likelihood: sequence of likelihoods\n",
    "    \"\"\"\n",
    "    pmf *= likelihood\n",
    "    pmf /= pmf.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use these functions to solve a new problem similar to the cookie problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Euro problem\n",
    "\n",
    "Here's a problem from David MacKay's book, [*Information Theory, Inference, and Learning Algorithms*](http://www.inference.org.uk/mackay/itila/p0.html), which is the book where I first learned about Bayesian statistics.  MacKay writes:\n",
    "\n",
    "> A statistical statement appeared in The Guardian on\n",
    "Friday January 4, 2002:\n",
    ">\n",
    "> >\"When spun on edge 250 times, a Belgian one-euro coin came\n",
    "up heads 140 times and tails 110. ‘It looks very suspicious\n",
    "to me’, said Barry Blight, a statistics lecturer at the London\n",
    "School of Economics. ‘If the coin were unbiased the chance of\n",
    "getting a result as extreme as that would be less than 7%’.\"\n",
    ">\n",
    "> But [asks MacKay] do these data give evidence that the coin is biased rather than fair?\n",
    "\n",
    "To answer this question, we have to make some modeling choices.\n",
    "\n",
    "* First, let's assume that if you spin a coin on edge, there is some probability that it will land heads up.  I'll call that probability $x$.\n",
    "\n",
    "* Second, let's assume that $x$ varies from one coin to the next, depending on how the coin is balanced and maybe some other factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these assumptions we can formulate MacKay's question as an inference problem: given the data --- 140 heads and 110 tails --- what do we think $x$ is for this coin?\n",
    "\n",
    "This formulation is similar to the 101 Bowls problem we saw in the previous notebook; in fact, we will use the same likelihoods.\n",
    "\n",
    "But in the 101 Bowls problem, we are told that we choose a bowl at random, which implies that all bowls have the same prior probability.\n",
    "\n",
    "For the Euro problem, we have to think harder.  What values of $x$ do you think are reasonable?\n",
    "\n",
    "It seems likely that many coins are \"fair\", meaning that the probability of heads is close to 50%.  Do you think there are coins where $x$ is 75%?  How about 90%?\n",
    "\n",
    "To be honest, I don't really know.  To get started, I will assume that all values of $x$, from 0% to 100%, are equally likely.  Then we'll come back and try another prior.\n",
    "\n",
    "Here's a uniform prior from 0 to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.arange(101)\n",
    "prior = 1/101\n",
    "pmf = make_pmf(xs, prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the likelihoods for heads and tails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood_heads = xs / 100\n",
    "likelihood_tails = 1 - xs / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are the updates for 140 heads and 110 tails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(140):\n",
    "    bayes_update(pmf, likelihood_heads)\n",
    "\n",
    "for i in range(110):\n",
    "    bayes_update(pmf, likelihood_tails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the results look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf.plot()\n",
    "\n",
    "plt.xlabel('Possible values of x')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('140 heads, 110 tails');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This curve shows the \"posterior distribution\" of $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Put a function on it\n",
    "\n",
    "Before we go on, let's put that update in a function, because we are going to need it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_update_euro(pmf, data):\n",
    "    \"\"\"Do a Bayesian update.\n",
    "    \n",
    "    pmf: Series that represents a prior PMF\n",
    "    data: tuple of number of heads, tails\n",
    "    \"\"\"\n",
    "    heads, tails = data\n",
    "    xs = pmf.index\n",
    "    \n",
    "    likelihood_heads = xs / 100\n",
    "    likelihood_tails = 1 - likelihood_heads\n",
    "\n",
    "    for i in range(heads):\n",
    "        bayes_update(pmf, likelihood_heads)\n",
    "\n",
    "    for i in range(tails):\n",
    "        bayes_update(pmf, likelihood_tails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes a PMF that represents the prior, and a tuple that contains the number of heads and tails.\n",
    "\n",
    "Here's the uniform prior again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.arange(101)\n",
    "prior = 1/101\n",
    "uniform = make_pmf(xs, prior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = 140, 110\n",
    "bayes_update_euro(uniform, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here are the results again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform.plot()\n",
    "\n",
    "plt.xlabel('Possible values of x')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('140 heads, 110 tails');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A better prior\n",
    "\n",
    "Remember that this result is based on a uniform prior, which assumes that any value of $x$ from 0 to 100 is equally likely.\n",
    "\n",
    "Given what we know about coins, that's probabily not true.  I can believe that if you spin a lop-sided coin on edge, it might be somewhat more likely to land on heads or tails.  \n",
    "\n",
    "But unless the coin is heavily weighted on one side, I would be surprised if $x$ were greater than 60% or less than 40%.\n",
    "\n",
    "Of course, I could be wrong, but in general I would expect to find $x$ closer to 50%, and I would be surprised to find it near 0% or 100%.\n",
    "\n",
    "I can represent that prior believe with a triangle-shaped prior.\n",
    "\n",
    "Here's an array that ramps up from 0 to 49 and ramps down from 50 to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramp_up = np.arange(50)\n",
    "ramp_down = np.arange(50, -1, -1)\n",
    "\n",
    "ps = np.append(ramp_up, ramp_down)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll put it in a PMF and normalize it so it adds up to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle = make_pmf(xs, ps)\n",
    "triangle /= triangle.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the triangle prior looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle.plot(color='C1')\n",
    "\n",
    "plt.xlabel('Possible values of x')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Triangle prior');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's update it with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the results, along with the posterior based on a uniform prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior distributions are almost identical because, in this case, we have enough data to \"swamp the prior\"; that is, the posteriors depend strongly on the data and only weakly on the priors.\n",
    "\n",
    "This is good news, because it suggests that we can use data to resolve arguments.  Suppose two people disagree about the correct prior.  If neither can persuade the other, they might have to agree to disagree.\n",
    "\n",
    "But if they get new data, and each of them does a Bayesian update, they will usually find their beliefs converging.\n",
    "\n",
    "And with enough data, the remaining difference can be so small that it makes no difference in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing the posterior distribution\n",
    "\n",
    "The posterior distribution contains all of the information we have about the value of $x$.  But sometimes we want to summarize this information.\n",
    "\n",
    "We have already seen one way to summarize a posterior distribution, the Maximum Aposteori Probability, or MAP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`idxmax` returns the value of $x$ with the highest probability.\n",
    "\n",
    "In this example, we get the same MAP with the triangle prior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "triangle.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to summarize the posterior distribution is the posterior mean.\n",
    "\n",
    "Given a set of quantities, $q_i$, and the corresponding probabilities, $p_i$, the mean of the distribution is:\n",
    "\n",
    "$\\sum_i q_i p_i$\n",
    "\n",
    "The following function takes a Pmf and computes its mean.  Note that this function only works correctly if the Pmf is normalized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmf_mean(pmf):\n",
    "    \"\"\"Compute the mean of a PMF.\n",
    "    \n",
    "    pmf: Series representing a PMF\n",
    "    \n",
    "    return: float\n",
    "    \"\"\"\n",
    "    return np.sum(pmf.index * pmf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the posterior mean based on the uniform prior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf_mean(uniform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's the posterior mean with the triangle prior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf_mean(triangle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The posterior means are not identical, but they are close enough that the difference probably doesn't matter.\n",
    "\n",
    "In this example, the posterior mean is very close to the MAP.  That's true when the posterior distribution is symmetric, but it is not always true.\n",
    "\n",
    "If someone asks what we think $x$ is, the MAP or the posterior mean might be a good answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior probability\n",
    "\n",
    "If the coin is \"fair\", that means that $x$ is 50%.  So it might be tempting to use the posterior PMF to compute the probability that $x$ is 50%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is the posterior probability that $x$ is 50%, but it is not the probability that the coin is fair.\n",
    "\n",
    "The problem is that $x$ is really a continuous quantity, which means it could have any value between 0 and 1.  \n",
    "\n",
    "For purposes of computation, I broke this interval into 101 discrete values, but that was an arbitrary choice.  I could have done the computation with 201 hypotheses, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs2 = np.linspace(0, 100, 201)\n",
    "prior2 = 1/201\n",
    "\n",
    "uniform2 = make_pmf(xs2, prior2)\n",
    "len(uniform2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_update_euro(uniform2, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's what the results look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform2.plot(color='C2')\n",
    "\n",
    "plt.xlabel('201 possible values of x')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('140 heads, 110 tails');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are visually similar, but you might notice that the curve is a little smoother at the peak.\n",
    "\n",
    "The MAPs are the same and the posterior means are almost the same:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform.idxmax(), uniform2.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmf_mean(uniform), pmf_mean(uniform2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the total probability is spread out over twice as many hypotheses, so the proability of any single hypothesis is smaller.\n",
    "\n",
    "If use both posteriors to compute the probability that $x$ is 50%, we get very different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform[50], uniform2[50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because $x$ is continuous, we divided the interval into discrete values.  But the number of values was an arbitrary choice, so the probability of any single value is not meaningful. \n",
    "\n",
    "However, we can meaningfully compute the probability that $x$ falls in an interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Credible intervals\n",
    "\n",
    "The following function takes a Pmf and an interval from `low` to `high`; it computes the total probability of all quantities in the interval (excluding `low` and including `high`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_between(pmf, low, high):\n",
    "    between = (low < pmf.index) & (pmf.index <= high)\n",
    "    total = pmf[between].sum()\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use it to compute the probability that $x$ is between 50 and 60, based on the uniform prior with 201 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_between(uniform2, 50, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability that $x$ is between 50 and 60 is about 88%.\n",
    "\n",
    "An interval like this is called a \"credible interval\" because it tells us how credible it is that $x$ falls in the interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, I chose the quantities, 50 and 60, and computed the posterior probability of the values between them.\n",
    "\n",
    "We can also go the other way: given a probability like 88%, we could find two quantities that have that much probability between them.\n",
    "To make that work in general, we have to do some interpolation, which is what the following function does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def credible_interval(pmf, prob):\n",
    "    \"\"\"Compute the mean of a PMF.\n",
    "    \n",
    "    pmf: Series representing a PMF\n",
    "    prob: probability of the interval\n",
    "    \n",
    "    return: pair of float\n",
    "    \"\"\"\n",
    "    # make the CDF\n",
    "    xs = pmf.index\n",
    "    ys = pmf.cumsum()\n",
    "    \n",
    "    # compute the probabilities\n",
    "    p = (1-prob)/2\n",
    "    ps = [p, 1-p]\n",
    "    \n",
    "    # interpolate the inverse CDF\n",
    "    options = dict(bounds_error=False,\n",
    "                   fill_value=(xs[0], xs[-1]), \n",
    "                   assume_sorted=True)\n",
    "    interp = interp1d(ys, xs, **options)\n",
    "    return interp(ps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The details of this function are not important right now, but we can confirm that it works as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "credible_interval(uniform, 0.88)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this lesson, we used data from a coin-spinning experiment to estimate the probability that a given coin lands on heads.\n",
    "\n",
    "We tried three different priors: uniform distributions with 101 and 201 values, and a triangle distribution.  The results are similar, which indicates that we have enough data to \"swamp the priors\".\n",
    "\n",
    "And we summarized the posterior distributions three ways, computing the value with Maximum Aposteori Probability (MAP), the posterior mean, and a credible interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Suppose a rookie baseball player gets 3 hits out of 3 at bats during their first game.  What do we think their long-term batting average will be?\n",
    "\n",
    "To answer this question, we have to make some modeling choices:\n",
    "\n",
    "* Let's assume that each player has some constant batting average that is their probability of getting a hit during any at bat.\n",
    "\n",
    "* As a prior distribution, let's use a normal distribution with mean 0.260 and standard deviation 0.033.\n",
    "\n",
    "We can use `scipy.stats.norm` to evaluate the normal distribution for a range of batting averages, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "mean = 0.26\n",
    "std = 0.033\n",
    "\n",
    "xs = np.linspace(0, 0.5, 101)\n",
    "ps = norm(mean, std).pdf(xs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can put these quantities and their probabilities in a Pmf, like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = make_pmf(xs, ps)\n",
    "prior /= prior.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what the prior distribution of batting averages looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior.plot(color='gray', label='prior')\n",
    "\n",
    "plt.xlabel('Batting average')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Distribution of batting averages')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Compute the likelihood of getting 3 hits.\n",
    "\n",
    "2. Compute the posterior distribution for this player's batting average.\n",
    "\n",
    "3. Plot the prior and posterior distributions.\n",
    "\n",
    "4. Compute the prior and posterior means; how much higher is the posterior mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
